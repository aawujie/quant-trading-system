"""AI Signal Enhancer"""

import json
import re
import logging
from typing import Dict, List, Optional

from app.ai.providers.base import AIProvider
from app.models.signals import SignalData
from app.models.market_data import KlineData
from app.models.indicators import IndicatorData

logger = logging.getLogger(__name__)


class AISignalEnhancer:
    """
    AIä¿¡å·å¢žå¼ºå™¨
    
    ä½¿ç”¨LLMå¯¹ä¼ ç»ŸæŠ€æœ¯æŒ‡æ ‡ä¿¡å·è¿›è¡ŒäºŒæ¬¡ç¡®è®¤å’Œå¢žå¼º
    
    åŠŸèƒ½ï¼š
    1. åˆ†æžå¸‚åœºçŽ¯å¢ƒå’ŒæŠ€æœ¯æŒ‡æ ‡
    2. è¯„ä¼°ä¿¡å·è´¨é‡å’Œé£Žé™©
    3. æä¾›æ‰§è¡Œå»ºè®®å’ŒæŽ¨ç†è¿‡ç¨‹
    4. è°ƒæ•´ä»“ä½å¤§å°å»ºè®®
    """
    
    def __init__(
        self,
        provider: AIProvider,
        enable_cache: bool = True,
        cache_size: int = 100
    ):
        """
        Args:
            provider: AIæä¾›è€…å®žä¾‹
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            cache_size: ç¼“å­˜å¤§å°
        """
        self.provider = provider
        self.enable_cache = enable_cache
        self.cache = {} if enable_cache else None
        self.cache_size = cache_size
        
        logger.info(
            f"AISignalEnhancer initialized: "
            f"provider={provider.get_model_name()}, cache={enable_cache}"
        )
    
    async def enhance_signal(
        self,
        signal: SignalData,
        kline: KlineData,
        indicator: IndicatorData,
        historical_trades: Optional[List[Dict]] = None
    ) -> Dict:
        """
        ä½¿ç”¨AIå¢žå¼ºä¿¡å·
        
        Args:
            signal: åŽŸå§‹äº¤æ˜“ä¿¡å·
            kline: å½“å‰Kçº¿æ•°æ®
            indicator: æŠ€æœ¯æŒ‡æ ‡æ•°æ®
            historical_trades: åŽ†å²äº¤æ˜“è®°å½•
        
        Returns:
            {
                'should_execute': True/False,
                'ai_confidence': 0.85,
                'reasoning': 'AIæŽ¨ç†è¿‡ç¨‹',
                'risk_assessment': 'low/medium/high',
                'position_size_multiplier': 0.8
            }
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._generate_cache_key(signal, kline, indicator)
        if self.enable_cache and cache_key in self.cache:
            logger.debug(f"Cache hit for signal: {signal.symbol}")
            return self.cache[cache_key]
        
        # æž„å»ºPrompt
        prompt = self._build_prompt(signal, kline, indicator, historical_trades)
        
        # è°ƒç”¨AI
        response = await self.provider.chat_completion(prompt, temperature=0.3)
        
        if not response:
            # AIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›žé»˜è®¤å€¼
            logger.warning("AI service unavailable, using default judgment")
            return {
                'should_execute': True,
                'ai_confidence': signal.confidence or 0.5,
                'reasoning': 'AIæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤åˆ¤æ–­',
                'risk_assessment': 'medium',
                'position_size_multiplier': 1.0
            }
        
        # è§£æžå“åº”
        decision = self._parse_response(response)
        
        # å­˜å…¥ç¼“å­˜
        if self.enable_cache:
            self._add_to_cache(cache_key, decision)
        
        return decision
    
    def _build_prompt(
        self,
        signal: SignalData,
        kline: KlineData,
        indicator: IndicatorData,
        historical_trades: Optional[List[Dict]]
    ) -> str:
        """
        æž„å»ºAIæç¤ºè¯
        
        åŒ…å«ï¼š
        1. å½“å‰å¸‚åœºæ•°æ®
        2. æŠ€æœ¯æŒ‡æ ‡
        3. ä¿¡å·ä¿¡æ¯
        4. åŽ†å²äº¤æ˜“è¡¨çŽ°
        """
        historical_summary = self._format_historical_trades(historical_trades) if historical_trades else "æ— åŽ†å²æ•°æ®"
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“åˆ†æžå¸ˆã€‚è¯·åˆ†æžä»¥ä¸‹äº¤æ˜“ä¿¡å·å¹¶ç»™å‡ºæ‰§è¡Œå»ºè®®ã€‚

## ðŸ“Š æŠ€æœ¯æŒ‡æ ‡ä¿¡å·
- **ç­–ç•¥**: {signal.strategy_name}
- **ä¿¡å·ç±»åž‹**: {signal.signal_type}
- **æ–¹å‘**: {signal.side}
- **æ“ä½œ**: {signal.action}
- **ä»·æ ¼**: ${signal.price:.2f}
- **åŽŸå› **: {signal.reason}
- **ç½®ä¿¡åº¦**: {signal.confidence:.2f if signal.confidence else 'N/A'}

## ðŸ’¹ å½“å‰å¸‚åœºæ•°æ®
- **äº¤æ˜“å¯¹**: {signal.symbol}
- **æœ€æ–°ä»·æ ¼**: ${kline.close:.2f}
- **24hé«˜ç‚¹**: ${kline.high:.2f}
- **24hä½Žç‚¹**: ${kline.low:.2f}
- **æˆäº¤é‡**: {kline.volume:.2f}

## ðŸ“ˆ æŠ€æœ¯æŒ‡æ ‡
- **RSI(14)**: {indicator.rsi14:.2f if indicator.rsi14 else 'N/A'}
- **MACD**: {indicator.macd_histogram:.4f if indicator.macd_histogram else 'N/A'}
- **MA(5/20)**: {indicator.ma5:.2f if indicator.ma5 else 'N/A'} / {indicator.ma20:.2f if indicator.ma20 else 'N/A'}
- **ATR(14)**: {indicator.atr14:.2f if indicator.atr14 else 'N/A'}
- **å¸ƒæž—å¸¦**: ä¸Šè½¨ {indicator.bb_upper:.2f if indicator.bb_upper else 'N/A'}, ä¸­è½¨ {indicator.bb_middle:.2f if indicator.bb_middle else 'N/A'}, ä¸‹è½¨ {indicator.bb_lower:.2f if indicator.bb_lower else 'N/A'}

## ðŸ“œ æœ€è¿‘äº¤æ˜“è¡¨çŽ°
{historical_summary}

## ðŸŽ¯ ä»»åŠ¡è¦æ±‚

è¯·åŸºäºŽä»¥ä¸Šä¿¡æ¯ï¼Œè¿›è¡Œæ·±åº¦åˆ†æžå¹¶ç»™å‡ºå»ºè®®ï¼š

1. **æŠ€æœ¯é¢åˆ†æž**: è¯„ä¼°å½“å‰æŠ€æœ¯æŒ‡æ ‡çš„å¼ºåº¦å’Œå¯é æ€§
2. **è¶‹åŠ¿åˆ¤æ–­**: åˆ¤æ–­å¸‚åœºå¤„äºŽè¶‹åŠ¿/éœ‡è¡çŠ¶æ€
3. **é£Žé™©è¯„ä¼°**: åˆ†æžæ½œåœ¨é£Žé™©ï¼ˆå¸‚åœºæ³¢åŠ¨ã€æ­¢æŸè·ç¦»ç­‰ï¼‰
4. **æ‰§è¡Œå»ºè®®**: æ˜¯å¦åº”è¯¥æ‰§è¡Œæ­¤ä¿¡å·ï¼Œä»¥åŠä»“ä½è°ƒæ•´å»ºè®®

**è¾“å‡ºæ ¼å¼**ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰ï¼š

```json
{{
    "should_execute": true,
    "ai_confidence": 0.75,
    "reasoning": "è¯¦ç»†çš„åˆ†æžæŽ¨ç†è¿‡ç¨‹ï¼ˆ100-200å­—ï¼‰",
    "risk_assessment": "low",
    "position_size_multiplier": 0.8
}}
```

**å­—æ®µè¯´æ˜Ž**ï¼š
- `should_execute`: æ˜¯å¦å»ºè®®æ‰§è¡Œï¼ˆtrue/falseï¼‰
- `ai_confidence`: AIç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
- `reasoning`: è¯¦ç»†æŽ¨ç†è¿‡ç¨‹
- `risk_assessment`: é£Žé™©è¯„ä¼°ï¼ˆlow/medium/highï¼‰
- `position_size_multiplier`: ä»“ä½è°ƒæ•´ç³»æ•°ï¼ˆ0.5-1.5ï¼‰
"""
        
        return prompt
    
    def _parse_response(self, response: str) -> Dict:
        """
        è§£æžAIå“åº”
        
        ä»Žå“åº”ä¸­æå–JSONæ ¼å¼çš„å†³ç­–
        """
        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                decision = json.loads(json_match.group())
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ['should_execute', 'ai_confidence', 'reasoning']
                if all(f in decision for f in required_fields):
                    # æ·»åŠ é»˜è®¤å€¼
                    decision.setdefault('risk_assessment', 'medium')
                    decision.setdefault('position_size_multiplier', 1.0)
                    
                    # éªŒè¯æ•°æ®ç±»åž‹å’ŒèŒƒå›´
                    decision['ai_confidence'] = max(0.0, min(1.0, float(decision['ai_confidence'])))
                    decision['position_size_multiplier'] = max(0.5, min(1.5, float(decision.get('position_size_multiplier', 1.0))))
                    
                    return decision
            
            # è§£æžå¤±è´¥
            logger.warning(f"Failed to parse AI response: {response[:200]}")
            return {
                'should_execute': False,
                'ai_confidence': 0.3,
                'reasoning': f'AIå“åº”æ ¼å¼é”™è¯¯ï¼š{response[:200]}',
                'risk_assessment': 'high',
                'position_size_multiplier': 1.0
            }
        
        except Exception as e:
            logger.error(f"Parse AI response error: {e}")
            return {
                'should_execute': False,
                'ai_confidence': 0.3,
                'reasoning': f'è§£æžå¤±è´¥ï¼š{str(e)}',
                'risk_assessment': 'high',
                'position_size_multiplier': 1.0
            }
    
    def _format_historical_trades(self, trades: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–åŽ†å²äº¤æ˜“è®°å½•
        
        è¿”å›žæ˜“è¯»çš„æ‘˜è¦å­—ç¬¦ä¸²
        """
        if not trades:
            return "æš‚æ— åŽ†å²äº¤æ˜“"
        
        lines = []
        for i, t in enumerate(trades[:5], 1):  # åªæ˜¾ç¤ºæœ€è¿‘5ç¬”
            side = t.get('side', 'UNKNOWN')
            pnl = t.get('pnl', 0)
            pnl_pct = t.get('pnl_pct', 0)
            
            result = "ç›ˆåˆ©" if pnl > 0 else "äºæŸ"
            lines.append(
                f"{i}. {side} - {result} ${pnl:.2f} ({pnl_pct*100:.2f}%)"
            )
        
        # è®¡ç®—ç»Ÿè®¡
        total_trades = len(trades)
        winning = sum(1 for t in trades if t.get('pnl', 0) > 0)
        win_rate = winning / total_trades if total_trades > 0 else 0
        
        summary = f"\næœ€è¿‘{len(trades)}ç¬”äº¤æ˜“ï¼ŒèƒœçŽ‡ {win_rate*100:.1f}%"
        
        return "\n".join(lines) + summary
    
    def _generate_cache_key(
        self,
        signal: SignalData,
        kline: KlineData,
        indicator: IndicatorData
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return (
            f"{signal.symbol}:{signal.signal_type}:{signal.timestamp}:"
            f"{kline.close:.2f}:{indicator.rsi14:.1f if indicator.rsi14 else 0}"
        )
    
    def _add_to_cache(self, key: str, value: Dict):
        """æ·»åŠ åˆ°ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰"""
        if not self.enable_cache:
            return
        
        # å¦‚æžœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
        if len(self.cache) >= self.cache_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[key] = value
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self.enable_cache:
            self.cache.clear()
            logger.info("AI cache cleared")

